# ============================================================================
# ğŸ‘¤ PERSON A: íŒŒì¼ 2: data/preprocessing.py
# ============================================================================

"""
ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë° SpecAugment êµ¬í˜„
"""

import torch
import numpy as np

class SpecAugment:
    """SpecAugment êµ¬í˜„"""
    def __init__(self, freq_mask_param=30, time_mask_param=40):
        self.freq_mask_param = freq_mask_param
        self.time_mask_param = time_mask_param

    
    def __call__(self, spectrogram):
        """
        Args:
            spectrogram: (freq, time) í˜•íƒœì˜ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨
        Returns:
            augmented_spectrogram
        """
        import torch
        import random

        augmented_spectrogram = spectrogram.clone()

        # TODO: SpecAugment ì ìš©
        # 1. FrequencyMasking ì ìš©
        num_freq_bins = augmented_spectrogram.size(0)
        f = random.randint(0, self.freq_mask_param)
        f0 = random.randint(0, max(0, num_freq_bins - f))
        augmented_spectrogram[f0:f0 + f, :] = 0

        # 2. TimeMasking ì ìš©
        num_time_bins = augmented_spectrogram.size(1)
        t = random.randint(0, self.time_mask_param)
        t0 = random.randint(0, max(0, num_time_bins - t))
        augmented_spectrogram[:, t0:t0 + t] = 0
        # 3. ê²°ê³¼ ë°˜í™˜
        return augmented_spectrogram


class AudioPreprocessor:
    """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬"""
    def __init__(self, sample_rate=16000, use_augment=False):
        self.sample_rate = sample_rate
        self.use_augment = use_augment
        if use_augment:
            self.augment = SpecAugment()
    
    def load_audio(self, audio_path):

        import soundfile as sf
        import numpy as np
        import torch
        import librosa

        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ë¦¬ìƒ˜í”Œë§
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            waveform: (sample_rate * duration,) í˜•íƒœì˜ í…ì„œ
        """
        # TODO: êµ¬í˜„
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        data, sr = sf.read(audio_path, always_2d=False)

        # 2. sample_rate í™•ì¸ ë° í•„ìš”ì‹œ ë¦¬ìƒ˜í”Œë§
        target_sr = self.sample_rate if hasattr(self, "sample_rate") else 16000
        if sr != target_sr:
            # librosaëŠ” (N,) í˜•íƒœë§Œ ë¦¬ìƒ˜í”Œ ê°€ëŠ¥
            if isinstance(data, np.ndarray) and data.ndim == 2:
                data = data.mean(axis=1)  # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜
            data = librosa.resample(np.asarray(data, dtype=np.float32), orig_sr=sr, target_sr=target_sr)
            sr = target_sr
        # numpy â†’ torch ë³€í™˜
        waveform = torch.tensor(data, dtype=torch.float32)

        # 3. ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (ìŠ¤í…Œë ˆì˜¤ë©´)
        if waveform.ndim == 1:
            waveform = waveform.unsqueeze(0)

        # 4. ë°˜í™˜
        return waveform, sr
    
    def normalize_audio(self, waveform):
        """
        ì˜¤ë””ì˜¤ ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
        
        Args:
            waveform: ì›ë³¸ waveform
        
        Returns:
            normalized_waveform
        """
        # TODO: êµ¬í˜„
        import torch
        # meanê³¼ stdë¥¼ ê³„ì‚°í•˜ì—¬ ì •ê·œí™”
        mean = torch.mean(waveform)
        std = torch.std(waveform)
        
        if std < 1e-8: # í‘œì¤€í¸ì°¨ê°€ 0ì— ê°€ê¹Œìš¸ ë•Œ (ë¬´ìŒ ë“±)
            return waveform - mean
        else: 
            return (waveform - mean) / (std + 1e-8)