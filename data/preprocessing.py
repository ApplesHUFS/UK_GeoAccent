# ============================================================================
# ğŸ‘¤ PERSON A: íŒŒì¼ 2: data/preprocessing.py
# ============================================================================

"""
ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë° SpecAugment êµ¬í˜„
"""

import torch
import torchaudio
import torchaudio.transforms as T
import numpy as np

class SpecAugment:
    """SpecAugment êµ¬í˜„"""
    def __init__(self, freq_mask_param=30, time_mask_param=40):
        self.freq_mask = T.FrequencyMasking(freq_mask_param=freq_mask_param)
        self.time_mask = T.TimeMasking(time_mask_param=time_mask_param)
    
    def __call__(self, spectrogram):
        """
        Args:
            spectrogram: (freq, time) í˜•íƒœì˜ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨
        Returns:
            augmented_spectrogram
        """
        # TODO: SpecAugment ì ìš©
        # 1. FrequencyMasking ì ìš©
        # 2. TimeMasking ì ìš©
        # 3. ê²°ê³¼ ë°˜í™˜
        pass

class AudioPreprocessor:
    """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬"""
    def __init__(self, sample_rate=16000, use_augment=False):
        self.sample_rate = sample_rate
        self.use_augment = use_augment
        if use_augment:
            self.augment = SpecAugment()
    
    def load_audio(self, audio_path):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ë¦¬ìƒ˜í”Œë§
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            waveform: (sample_rate * duration,) í˜•íƒœì˜ í…ì„œ
        """
        # TODO: êµ¬í˜„
        # 1. torchaudio.load()ë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
        # 2. sample_rate í™•ì¸ ë° í•„ìš”ì‹œ ë¦¬ìƒ˜í”Œë§
        # 3. ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (ìŠ¤í…Œë ˆì˜¤ë©´)
        # 4. ë°˜í™˜
        pass
    
    def normalize_audio(self, waveform):
        """
        ì˜¤ë””ì˜¤ ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
        
        Args:
            waveform: ì›ë³¸ waveform
        
        Returns:
            normalized_waveform
        """
        # TODO: êµ¬í˜„
        # meanê³¼ stdë¥¼ ê³„ì‚°í•˜ì—¬ ì •ê·œí™”
        pass