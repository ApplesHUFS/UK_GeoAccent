# ============================================================================
# ðŸ‘¤ PERSON A: íŒŒì¼ 3: data/dataset.py
# ============================================================================

"""
Custom PyTorch Dataset êµ¬í˜„
"""

import torch
from torch.utils.data import Dataset
from datasets import load_dataset
from data.data_config import (
    DATASET_NAME, REGION_LABELS, GENDER_LABELS,
    REGION_COORDS, normalize_coords, AUDIO_SAMPLE_RATE
)
from data.preprocessing import AudioPreprocessor

class EnglishDialectsDataset(Dataset):
    """
    English Dialects ë°ì´í„°ì…‹
    
    ë ˆì´ë¸” í˜•ì‹: 'irish_male', 'irish_female', 'midlands_male', ... ë“±
    ìš°ë¦¬ëŠ” ë©”ì¸ ë ˆì´ë¸”: ì§€ì—­ (6ê°œ)
         ë³´ì¡° ë ˆì´ë¸”: ì„±ë³„ (2ê°œ)
    """
    
    def __init__(self, split='train', use_augment=False, processor=None):

        # TODO: êµ¬í˜„
        super().__init__()
        self.split = split
        self.use_augment = use_augment
        self.processor = processor

        
        # 1. HuggingFace datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë°ì´í„°ì…‹ ë¡œë“œ
        from datasets import load_dataset, concatenate_datasets, Value
        dataset_name = "ylacombe/english_dialects"

        configs = [
        "irish_male", "midlands_female", "midlands_male",
        "northern_female", "northern_male",
        "scottish_female", "scottish_male",
        "southern_female", "southern_male",
        "welsh_female", "welsh_male"
        ]

        datasets_list = []
        for cfg in configs:
            ds_cfg = load_dataset(dataset_name, cfg, split=split)
            ds_cfg = ds_cfg.add_column("config_name", [cfg] * len(ds_cfg))
            datasets_list.append(ds_cfg)

        hf_ds = concatenate_datasets(datasets_list)
        self.dataset = hf_ds
        print(f"âœ… Loaded all dialect configs. Total samples: {len(self.dataset)}")

        '''
        # 2. splitë³„ë¡œ ë°ì´í„° í•„í„°ë§
        if "split" in hf_ds.column_names:
            hf_ds = hf_ds.filter(lambda ex: ex["split"] == split)
        '''

         # âœ… ì—¬ê¸°ì„œ dataset ì €ìž¥
        self.dataset = hf_ds

        # 3. ë ˆì´ë¸” íŒŒì‹± (ì˜ˆ: 'irish_male' -> region='irish', gender='male')
        def _parse_label(label_str: str):
            tok = (
                label_str.lower()
                .replace("-", "_")
                .replace(" ", "_")
                .strip("_")
            )
            parts = tok.split("_")
            region = parts[0] if len(parts) > 0 else None
            gender = parts[1] if len(parts) > 1 else None

            if region not in REGION_LABELS:
                raise ValueError(f"Unknown region label: {region} (from '{label_str}')")
            if gender not in GENDER_LABELS:
                raise ValueError(f"Unknown gender label: {gender} (from '{label_str}')")

            region_id = REGION_LABELS[region]
            gender_id = GENDER_LABELS[gender]
            lat, lon = REGION_COORDS[region]
            nlat, nlon = normalize_coords(lat, lon)
            return region, gender, region_id, gender_id, (nlat, nlon)

        self._parse_label = _parse_label

        # 4. ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        #self.dataset = None
        self.audio_preprocessor = AudioPreprocessor(
            sample_rate=AUDIO_SAMPLE_RATE,
            use_augment=use_augment
        )
        self.processor = processor
    
    def __len__(self):
        '''ì „ì²´ ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜'''
        return len(self.dataset)
    
    def __getitem__(self, idx):
        sample = self.dataset[idx]

        # 1. ì´ë¯¸ ë””ì½”ë”©ëœ ì˜¤ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°
        audio = sample["audio"]
        waveform = torch.tensor(audio["array"], dtype=torch.float32).unsqueeze(0)
        sr = audio["sampling_rate"]

        # 2. ì •ê·œí™”
        waveform = self.audio_preprocessor.normalize_audio(waveform)

        # 3. ë ˆì´ë¸” íŒŒì‹±
        config_name = sample["config_name"]  # ì˜ˆ: 'irish_male'
        region, gender, region_id, gender_id, coords = self._parse_label(config_name)

        return {
            "waveform": waveform,
            "sample_rate": sr,
            "region_id": region_id,
            "gender_id": gender_id,
            "coords": coords,
            "config_name": config_name #1
        }

   
def collate_fn(batch):
    """
    DataLoaderìš© collate function
    - ê°€ë³€ ê¸¸ì´ ì˜¤ë””ì˜¤ë¥¼ padding
    - ë ˆì´ë¸”ì€ ê·¸ëŒ€ë¡œ í…ì„œë¡œ ë³€í™˜
    """
    import torch

    # 1. ë°°ì¹˜ì—ì„œ input_values ì¶”ì¶œ ë° padding (waveformì€ (1, T) í˜•íƒœ)
    lengths = [b["waveform"].shape[-1] for b in batch]
    max_len = int(max(lengths))
    bs = len(batch)

    input_values = torch.zeros(bs, max_len, dtype=torch.float32)
    attention_mask = torch.zeros(bs, max_len, dtype=torch.long)

    for i, b in enumerate(batch):
        w = b["waveform"].squeeze(0)  # (T,)
        L = w.shape[0]
        input_values[i, :L] = w
        attention_mask[i, :L] = 1    
    
    # 2) ë¼ë²¨ ìŠ¤íƒ
    region_labels = torch.tensor([b["region_id"] for b in batch], dtype=torch.long)
    gender_labels = torch.tensor([b["gender_id"] for b in batch], dtype=torch.long)

    # 3) ì¢Œí‘œ ìŠ¤íƒ (nlat, nlon) -> (B, 2)
    coords = torch.tensor([b["coords"] for b in batch], dtype=torch.float32)

    # 4) dictë¡œ ë°˜í™˜
    return {
        "input_values": input_values,        # (B, T_max)
        "attention_mask": attention_mask,    # (B, T_max)
        "region_labels": region_labels,      # (B,)
        "gender_labels": gender_labels,      # (B,)
        "coords": coords                     # (B, 2)
    }

