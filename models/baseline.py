# ============================================================================
# ğŸ‘¤ PERSON B: ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¦¬ë“œ
# íŒŒì¼ 1: models/baseline.py
# ============================================================================

"""
ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸: Wav2Vec2 + Classification Head
- Multi-task learning (ì§€ì—­ ë¶„ë¥˜ + ì„±ë³„ ë¶„ë¥˜)
"""

import torch
import torch.nn as nn
from transformers import Wav2Vec2Model, Wav2Vec2Config

class Wav2Vec2Baseline(nn.Module):
    """
    Wav2Vec2 ê¸°ë°˜ ì–µì–‘ ë¶„ë¥˜ ëª¨ë¸
    
    êµ¬ì¡°:
    - Wav2Vec2Model (ì‚¬ì „í•™ìŠµ ëª¨ë¸)
    - Temporal pooling (í‰ê· )
    - Classification head (ì§€ì—­ + ì„±ë³„ ë¶„ë¥˜)
    """
    
    def __init__(self, model_name="facebook/wav2vec2-xls-r-300m", num_regions=6, num_genders=2):
        """
        Args:
            model_name: HuggingFace pretrained ëª¨ë¸ ì´ë¦„
            num_regions: ì§€ì—­ í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ 6)
            num_genders: ì„±ë³„ í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ 2)
        """
        super().__init__()
        
        # Wav2Vec2 ëª¨ë¸ ë¡œë“œ
        self.wav2vec2 = Wav2Vec2Model.from_pretrained(model_name)
        self.hidden_size = self.wav2vec2.config.hidden_size  # ë³´í†µ 1024 or 768
        
        # Classification head
        # TODO: êµ¬í˜„
        # 1. Dropout layer
        # 2. Region classifier (linear layer: hidden_size -> num_regions)
        # 3. Gender classifier (linear layer: hidden_size -> num_genders)
        
        self.num_regions = num_regions
        self.num_genders = num_genders
    
    def forward(self, input_values, attention_mask=None):
        """
        Args:
            input_values: (batch_size, seq_length) - ì˜¤ë””ì˜¤ íŒŒí˜•
            attention_mask: (batch_size, seq_length) - padding mask
        
        Returns:
            dict: {
                'region_logits': (batch_size, num_regions),
                'gender_logits': (batch_size, num_genders),
                'pooled_hidden': (batch_size, hidden_size) - ì‹œê°í™”ìš©
            }
        """
        # TODO: êµ¬í˜„
        # 1. Wav2Vec2ë¡œ feature ì¶”ì¶œ
        #    outputs = self.wav2vec2(input_values, attention_mask=attention_mask)
        #    last_hidden = outputs.last_hidden_state  # (batch_size, seq_length, hidden_size)
        #
        # 2. Temporal pooling (í‰ê· )
        #    if attention_mask is not None:
        #        # maskëœ ë¶€ë¶„ ì œì™¸í•˜ê³  í‰ê· 
        #    else:
        #        pooled = last_hidden.mean(dim=1)  # (batch_size, hidden_size)
        #
        # 3. Classification
        #    region_logits = self.region_classifier(pooled)
        #    gender_logits = self.gender_classifier(pooled)
        #
        # 4. ë°˜í™˜
        pass